<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Forecasting Apps ‚Äì User Guide</title>
  <style>
    :root {
      --bg: #0b1220;
      --panel: #151c2f;
      --panel-2: #0f1630;
      --text: #e7ecf5;
      --muted: #b9c2d3;
      --accent: #6aa9ff;
      --accent-2: #ffb86b;
      --ok: #43d17c;
      --warn: #ffc857;
      --danger: #ff7676;
      --info: #2b6cb0;
    }
    html, body { background: var(--bg); color: var(--text); font-family: Inter, Segoe UI, Roboto, Helvetica, Arial, sans-serif; margin: 0; }
    .wrap { max-width: 1080px; margin: 0 auto; padding: 32px 20px 60px; }
    h1 { margin: 0 0 8px; font-size: 32px; }
    h2 { margin-top: 28px; font-size: 22px; }
    h3 { margin-top: 22px; font-size: 18px; color: var(--accent); }
    p, li { color: var(--muted); line-height: 1.65; }
    code, .kbd { background: #0e1a33; color: #d6e1ff; padding: 0 6px; border-radius: 4px; }
    .topbar { display: flex; gap: 12px; align-items: center; margin: 14px 0 24px; color: var(--muted); }
    .chip { background: #0e1a2c; border: 1px solid #1f2a44; padding: 6px 10px; border-radius: 999px; font-size: 12px; }
    .tabs { display: flex; gap: 8px; border-bottom: 1px solid #1f2a44; margin-top: 10px; }
    .tab { padding: 10px 14px; cursor: pointer; border: 1px solid transparent; border-top-left-radius: 6px; border-top-right-radius: 6px; color: var(--muted); }
    .tab.active { color: var(--text); background: var(--panel); border-color: #1f2a44; border-bottom-color: transparent; }
    .panel { display: none; background: var(--panel); border: 1px solid #1f2a44; border-top: none; padding: 18px 20px 24px; border-bottom-left-radius: 6px; border-bottom-right-radius: 6px; }
    .panel.active { display: block; }
    .infobox { background: #0f203d; border: 1px solid #254980; padding: 12px 14px; border-radius: 6px; margin: 12px 0; }
    .infobox strong { color: #cfe3ff; }
    .callout { display: grid; gap: 6px; padding: 10px 12px; border-radius: 6px; }
    .callout.info { background: #0c253e; border: 1px solid #234b71; }
    .callout.ok { background: #0d2b21; border: 1px solid #246a4d; }
    .callout.warn { background: #2a230f; border: 1px solid #6a5a24; }
  /* Banner-style alert: no awkward word wrapping */
  .banner { display: block; text-align: center; font-weight: 600; line-height: 1.5; word-break: normal; white-space: normal; }
  .banner strong { color: #fff; }
    .grid { display: grid; gap: 14px; grid-template-columns: repeat(auto-fit, minmax(260px, 1fr)); }
    .card { background: var(--panel-2); border: 1px solid #1f2a44; border-radius: 8px; padding: 14px; }
    .kpis { display: grid; grid-template-columns: repeat(auto-fit, minmax(160px, 1fr)); gap: 10px; }
    .kpi { background: #0d1426; border: 1px solid #1f2a44; padding: 10px 12px; border-radius: 8px; }
    a { color: var(--accent); text-decoration: none; }
    a:hover { text-decoration: underline; }
    .small { font-size: 13px; }
    .mono { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace; }
    .muted { color: var(--muted); }
  </style>
</head>
<body>
  <div class="wrap">
    <h1>Forecasting Apps ‚Äì User Guide</h1>
    <div class="topbar">
      <span class="chip">Covers: Forecaster App &amp; Quarterly Outlook Forecaster</span>
      <span class="chip">Backtesting &amp; Auto (per product)</span>
      <span class="chip">Offline HTML</span>
    </div>

    <div class="callout warn banner" role="alert">
      ‚ö†Ô∏è Important: Double‚Äëclick the <span class="mono">.BAT</span> files from <strong>File Explorer</strong> to run the apps. <strong>.BAT files will not run from a web browser.</strong>
    </div>

    <p class="small">Setup instructions live in <strong>SETUP_GUIDE.html</strong>. This guide explains how to use both apps after setup, how models are chosen, and how backtesting &amp; Auto selection work.</p>

    <div class="tabs" role="tablist" aria-label="Apps">
      <button id="tab-forecaster" class="tab active" role="tab" aria-controls="panel-forecaster" aria-selected="true">Forecaster App</button>
      <button id="tab-outlook" class="tab" role="tab" aria-controls="panel-outlook" aria-selected="false">Quarterly Outlook Forecaster</button>
    </div>

    <!-- Forecaster App Panel -->
    <section id="panel-forecaster" class="panel active" role="tabpanel" aria-labelledby="tab-forecaster">
      <h2>What it does</h2>
      <p>The Forecaster App builds product-level forecasts from your historical time series and compares multiple model families. Results and rationale are surfaced directly in the UI along with downloads.</p>

      <div class="grid">
        <div class="card">
          <h3>Quick start</h3>
          <ol>
            <li>Open the app via <span class="mono">Forecaster App/RUN_FORECAST_APP.bat</span>.</li>
            <li>Upload your Excel/CSV file with Date, Product, and ACR columns. Configure sidebar settings (models, horizon, backtesting options).</li>
            <li>The app automatically defaults to <strong>Best per Product (Backtesting)</strong> - the recommended approach for highest accuracy.</li>
            <li>Review results summary showing WAPE, confidence levels, and model selection breakdown (e.g., "SARIMA 57%, ETS 43%").</li>
            <li>Use the model dropdown to compare different approaches. Apply Live Conservatism adjustments (90-110%) for scenario planning.</li>
            <li>Download results with your adjustments automatically included in the exported data and filenames.</li>
          </ol>
        </div>
        <div class="card">
          <h3>Data expectations</h3>
          <ul>
            <li>Regular time index (daily/weekly/monthly). Missing dates are allowed; the app will handle common gaps.</li>
            <li>At least ~12‚Äì18 periods per product recommended for meaningful evaluation; more improves backtesting.</li>
            <li>Stable identifiers for products or groups to segment forecasts.</li>
          </ul>
          <p class="small muted">If data are very sparse or volatile, backtesting may fall back to simpler windows or Standard selection.</p>
        </div>
      </div>

      <h2>Model Selection Approaches</h2>
      <div class="infobox">
        <p><strong>Best per Product (Backtesting) - Recommended:</strong> Uses rigorous walk-forward backtesting to select the best model for each product individually. Employs strict eligibility criteria (enough history for ‚â•4 folds, stability checks) and business-aware safeguards. Shows recency‚Äëweighted WAPE from actual backtesting performance.</p>
        <p><strong>Best per Product (Standard):</strong> Multi-metric ranking approach using validation data. Ranks models across WAPE, SMAPE, MASE, and RMSE, then selects best average rank per product. More robust to outliers, works with shorter history.</p>
        <p><strong>Individual Models:</strong> Choose a single model (SARIMA, ETS, Prophet, etc.) for all products. Useful when you want consistency or have domain expertise about which model works best for your business.</p>
      </div>

      <h2>Rigorous Backtesting Methodology</h2>
      <ul>
        <li><strong>Walk-forward validation:</strong> Expanding-window backtests over an <strong>adjustable backtest period</strong> (default <strong>15 months</strong>) with a <strong>3‚Äëmonth validation horizon</strong> per fold (‚âà4‚Äì6 folds), creating multiple out-of-sample validation windows with recency weighting.</li>
        <li><strong>Strict eligibility:</strong> Requires enough history for ‚â•4 folds, MASE &lt; 1.0 (LightGBM &lt; 0.8), ‚â•10% better WAPE than Seasonal‚ÄëNaive, and stability checks (p95 WAPE ‚â§ 2.25√ó mean, up to 2.5√ó with high fold consistency).</li>
        <li><strong>WAPE-first scoring:</strong> Primary ranking by recency‚Äëweighted mean WAPE, with tie-breaks using p75 WAPE ‚Üí MASE ‚Üí trend‚Äëimprovement check.</li>
        <li><strong>Business-aware safeguards:</strong> Polynomial models deprioritized for revenue forecasting; fallback to Seasonal-Naive or ETS when eligibility fails.</li>
      </ul>

      <h3>Recommended settings</h3>
      <ul>
        <li><strong>Backtesting parameters:</strong> Automatically optimized - Gap = <strong>0 months</strong>; Horizon = <strong>3 months</strong> (quarterly validation); Backtest period = <strong>15 months</strong> for ~4‚Äì6 folds.</li>
        <li><strong>Requirements:</strong> Typically requires ~30+ months for full backtesting; automatically falls back to Standard with shorter history.</li>
        <li><strong>No manual configuration needed:</strong> Parameters optimized for revenue forecasting scenarios.</li>
      </ul>
      <p class="small muted">Walk‚Äëforward uses optimized parameters and needs roughly <strong>30+ months</strong> of history for best results. With less history, the app automatically falls back to Standard mode.</p>

      <h2>Models compared</h2>
      <div class="grid">
        <div class="card"><h3>SARIMA / ETS</h3><p>Classical time-series baselines with trend/seasonality. Good for well-behaved series.</p></div>
        <div class="card"><h3>Prophet</h3><p>Additive trend with seasonality/holidays; resilient to missing data and shifts.</p></div>
        <div class="card"><h3>Auto-ARIMA</h3><p>Automated order selection for ARIMA/SARIMA; fast and competitive on many series.</p></div>
        <div class="card"><h3>LightGBM</h3><p>Gradient-boosted trees on engineered calendar/lag features; handles complex patterns.</p></div>
        <div class="card"><h3>Polynomial</h3><p>Business-friendly baselines with guardrails to prevent overfit; included in ranking.</p></div>
      </div>

      <h2>Live Conservatism Feature</h2>
      <div class="infobox">
        <p><strong>üéõÔ∏è Real-Time Forecast Adjustment:</strong> The Live Conservatism slider allows you to apply instant haircuts or uplifts to your forecasts without re-running the models. Perfect for scenario planning and conservative estimates.</p>
      </div>
      
      <div class="grid">
        <div class="card">
          <h3>How It Works</h3>
          <ul>
            <li><strong>Location:</strong> Appears in sidebar under "Select Models" after your first forecast</li>
            <li><strong>Range:</strong> 90-110% with 1% precision (e.g., 97% for 3% haircut)</li>
            <li><strong>Scope:</strong> Only adjusts forecast rows, preserves historical actuals</li>
            <li><strong>Speed:</strong> Instant updates to charts, totals, and metrics</li>
          </ul>
        </div>
        <div class="card">
          <h3>Common Use Cases</h3>
          <ul>
            <li><strong>Conservative planning:</strong> 95-97% for cautious estimates</li>
            <li><strong>Optimistic scenarios:</strong> 102-105% for growth targets</li>
            <li><strong>Management adjustments:</strong> Quick what-if analysis</li>
            <li><strong>Risk management:</strong> Stress testing forecast sensitivity</li>
          </ul>
        </div>
      </div>

      <div class="callout info">
        <p><strong>Export Integration:</strong> All downloads (Excel/CSV) automatically include your conservatism adjustments. Filenames show the factor (e.g., <code>_conservatism97pct</code>) and success messages confirm when adjustments are included.</p>
      </div>

      <h2>Understanding the Results Interface</h2>
      <div class="kpis">
        <div class="kpi"><strong>Results Summary</strong><br><span class="muted">Shows overall WAPE, confidence level, model breakdown percentages, and total forecast amount.</span></div>
        <div class="kpi"><strong>Model Dropdown</strong><br><span class="muted">Defaults to "Best per Product (Backtesting)" but allows comparison with other approaches. Shows WAPE percentage for selected model.</span></div>
        <div class="kpi"><strong>Forecast Totals</strong><br><span class="muted">Product-level forecast amounts with individual product charts and performance indicators.</span></div>
        <div class="kpi"><strong>Interactive Features</strong><br><span class="muted">Live Conservatism slider (90-110%), download results with adjustments, view backtesting details, and access diagnostic information.</span></div>
      </div>

      <h2>Troubleshooting & Best Practices</h2>
      <ul>
        <li><strong>Short history (&lt;24 months):</strong> App automatically falls back to Best per Product (Standard) with multi-metric ranking.</li>
        <li><strong>Zero/near-zero actuals:</strong> WAPE handles this better than MAPE, but very sparse data may still be challenging.</li>
        <li><strong>High WAPE (&gt;30%):</strong> Use the Live Conservatism slider for quick adjustments, check for outliers, or use longer historical periods.</li>
        <li><strong>Polynomial warnings:</strong> Business-aware selection is enabled by default to prioritize seasonal models over polynomial fits for revenue data.</li>
        <li><strong>Model comparison:</strong> Use the dropdown to compare individual models with composite approaches; composite often wins.</li>
        <li><strong>Live adjustments:</strong> Conservatism slider preserves your baseline - you can always return to 100% without re-running forecasts.</li>
      </ul>
    </section>

    <!-- Outlook Panel -->
    <section id="panel-outlook" class="panel" role="tabpanel" aria-labelledby="tab-outlook">
      <h2>What it does</h2>
      <p>The Quarterly Outlook Forecaster (Daily Data Edition) projects quarter performance from partial in-quarter data using sophisticated quarterly backtesting with business-oriented validation rules. Features intelligent model selection that only allows backtested models, ensuring production-ready forecasts with overfitting protection.</p>

      <div class="grid">
        <div class="card">
          <h3>Quick start</h3>
          <ol>
            <li>Open the app via <span class="mono">Quarter Outlook App/RUN_OUTLOOK_FORECASTER.bat</span>.</li>
            <li>Use the <strong>Data Upload</strong> tab to load your daily data (date, product ID/name, measure columns).</li>
            <li>Review <strong>Outlook Results</strong> - app automatically uses Sophisticated Quarterly Backtesting (default).</li>
            <li>Examine the enhanced validation strategy explanation and WAPE performance summary.</li>
            <li>Analyze charts with purple dotted lines showing actual backtesting prediction trends.</li>
            <li>Expand "Backtesting Validation Breakdown" for detailed fold-by-fold performance.</li>
            <li>Download comprehensive results including monthly breakdowns and validation details.</li>
          </ol>
        </div>
        <div class="card">
          <h3>Data requirements</h3>
          <ul>
            <li><strong>Optimal:</strong> ‚â•180 days for Sophisticated Quarterly Backtesting with 8-12 weekly validation folds.</li>
            <li><strong>Minimum:</strong> ‚â•14 days for Enhanced Daily Backtesting (2-day horizon validation).</li>
            <li><strong>Fallback:</strong> <14 days uses Standard mode (rare, basic statistical validation).</li>
            <li>Daily grain with consistent product identifiers across the fiscal year period.</li>
            <li>Current quarter partial data + historical data for robust model training.</li>
          </ul>
        </div>
      </div>

      <h2>Sophisticated Quarterly Backtesting (Default)</h2>
      <div class="callout info">
        <div><strong>üèÜ Enhanced Validation Strategy:</strong> The app automatically uses advanced quarterly backtesting optimized for daily-to-quarterly forecasting with strict business rules for production-ready accuracy.</div>
      </div>
      
      <div class="grid">
        <div class="card">
          <h3>Training & Validation</h3>
          <ul>
            <li><strong>Training Window:</strong> Rolling 180-365 days (min 180, default 365, never <90)</li>
            <li><strong>Validation Folds:</strong> 8-12 weekly folds per quarter (preferably Fridays)</li>
            <li><strong>Dynamic Horizon:</strong> Forecast from origin date through quarter-end</li>
            <li><strong>Gap Protection:</strong> Prevents data leakage with intelligent lag handling</li>
          </ul>
        </div>
        <div class="card">
          <h3>Business-Aware Metrics</h3>
          <ul>
            <li><strong>Primary:</strong> WAPE on remaining-quarter sum (revenue-aligned)</li>
            <li><strong>Secondary:</strong> WAPE on quarter total (full-quarter accuracy)</li>
            <li><strong>Tertiary:</strong> Daily MASE (statistical robustness)</li>
            <li><strong>EOQ Penalty:</strong> 1.25x penalty for poor end-of-quarter performance</li>
          </ul>
        </div>
        <div class="card">
          <h3>Recency Weighting</h3>
          <ul>
            <li><strong>Historical Folds:</strong> Exponential decay with 2-quarter half-life</li>
            <li><strong>Current Quarter:</strong> Additional 28-day half-life weighting</li>
            <li><strong>Focus:</strong> Recent validation folds weighted heavily for relevance</li>
          </ul>
        </div>
        <div class="card">
          <h3>Model Selection Rules</h3>
          <ul>
            <li><strong>Strict Policy:</strong> Only backtested models allowed (no fallback)</li>
            <li><strong>Overfitting Protection:</strong> Models must pass validation to be selected</li>
            <li><strong>Fallback:</strong> 'Run Rate' if all models fail backtesting</li>
            <li><strong>Transparency:</strong> Detailed fold-by-fold breakdown available</li>
          </ul>
        </div>
      </div>

      <h2>Visual Chart Features</h2>
      <div class="grid">
        <div class="card">
          <h3>üî∫ Green Triangles</h3>
          <p>Validation start points showing where each backtesting fold begins its prediction period. These mark the exact dates when the model started forecasting during validation.</p>
        </div>
        <div class="card">
          <h3>üìà Purple Dotted Lines</h3>
          <p>Actual backtesting prediction trends from each validation fold. Shows how the model actually performed during walk-forward validation, not just summary statistics.</p>
        </div>
        <div class="card">
          <h3>üìä Enhanced Titles</h3>
          <p>Chart titles display both Standard and Backtesting WAPE with fold counts and "‚úì Walk-Forward Validated" indicators for transparency.</p>
        </div>
        <div class="card">
          <h3>üìã Interactive Details</h3>
          <p>Expand "Backtesting Validation Breakdown" to see detailed metrics for each validation fold including iterations, weighted WAPE, and performance statistics.</p>
        </div>
      </div>

      <h2>Reading the Enhanced UI</h2>
      <div class="kpis">
        <div class="kpi"><strong>Enhanced Strategy Box</strong><br><span class="muted">Blue info box explaining why backtesting is always used, with validation summary and method counts.</span></div>
        <div class="kpi"><strong>Interactive Charts</strong><br><span class="muted">Green triangles = validation points, Purple dotted lines = backtesting predictions, Enhanced titles with WAPE metrics.</span></div>
        <div class="kpi"><strong>Validation Breakdown</strong><br><span class="muted">Expandable section showing detailed fold-by-fold validation results with iterations and weighted metrics.</span></div>
        <div class="kpi"><strong>Model Comparison</strong><br><span class="muted">Tables showing Standard WAPE, Backtesting WAPE, and Enhanced Score for transparency.</span></div>
      </div>

      <h2>FAQ & Troubleshooting</h2>
      <ul>
        <li><strong>Why do purple lines not show?</strong> Indicates validation fold issues; check the "Backtesting Validation Breakdown" section for detailed fold results and any error messages.</li>
        <li><strong>Why does my product show "Enhanced Daily Backtesting"?</strong> When data is 14-179 days, app uses 2-day horizon validation instead of quarterly backtesting for optimal accuracy.</li>
        <li><strong>What if I have high quarterly backtesting WAPE?</strong> Check EOQ penalty impact, review training window adequacy (180-365 days), and verify data quality in recent periods.</li>
        <li><strong>Why do I see fewer than 8-12 validation folds?</strong> Limited recent history; optimal is weekly folds but app adapts to available data.</li>
        <li><strong>Can I override the backtesting-first approach?</strong> No - this ensures production-ready forecasts with overfitting protection. If all models fail backtesting, app automatically falls back to 'Run Rate'.</li>
      </ul>
    </section>

    <h2>Key Metrics & Terminology</h2>
    <div class="grid">
      <div class="card">
        <h3>WAPE (Primary Metric)</h3>
        <p><strong>Weighted Absolute Percentage Error:</strong> sum(|Actual - Forecast|) / sum(|Actual|). Revenue-aligned accuracy measure that weights errors by dollar amounts. 15% WAPE = forecasts typically within 15% of actual revenue.</p>
      </div>
      <div class="card">
        <h3>WAPE Accuracy Levels</h3>
        <p><strong>0-10%:</strong> Excellent accuracy. <strong>10-20%:</strong> Good accuracy. <strong>20-30%:</strong> Moderate accuracy. <strong>30%+:</strong> Lower accuracy, consider manual adjustments.</p>
      </div>
      <div class="card">
        <h3>Multi-Metric Ranking</h3>
        <p>Models ranked across WAPE, SMAPE, MASE, and RMSE for robustness. Best average rank across all metrics wins per product.</p>
      </div>
      <div class="card">
        <h3>Sophisticated Quarterly Backtesting</h3>
        <p>Advanced walk-forward validation with 180-365 day rolling training windows, 8-12 weekly validation folds, dynamic quarter-end horizons, and business-aware recency weighting.</p>
      </div>
      <div class="card">
        <h3>Enhanced Daily Backtesting</h3>
        <p>Optimized validation for shorter history (14-179 days) using 2-day horizon with heavy weighting of recent performance for daily quarterly forecasting.</p>
      </div>
      <div class="card">
        <h3>EOQ (End-of-Quarter) Penalty</h3>
        <p>1.25x penalty applied when forecasting error in the last 5 business days of a quarter exceeds 30% threshold, ensuring strong quarter-end performance.</p>
      </div>
      <div class="card">
        <h3>Recency Weighting</h3>
        <p>Multi-layered exponential decay: 2-quarter half-life for historical folds + 28-day half-life within current quarter, ensuring recent performance dominates model selection.</p>
      </div>
      <div class="card">
        <h3>Validation Folds</h3>
        <p>Individual train/test splits within walk-forward validation. Quarterly backtesting uses 8-12 weekly folds (preferably Fridays) starting near end of available history.</p>
      </div>
      <div class="card">
        <h3>Overfitting Protection</h3>
        <p>Strict policy allowing only backtested models to be selected, preventing models that perform well on training data but poorly on unseen data from being chosen.</p>
      </div>
    </div>

    <div class="callout info" style="margin-top:20px;">
      <div><strong>Related:</strong> See <span class="mono">Forecaster App/modules/tab_content.py</span> Model Guide for a deeper in-app explanation of modes and backtesting.</div>
    </div>

    <p class="small muted" style="margin-top:18px;">This guide describes behavior implemented in the current project: multi-model comparison (SARIMA/ETS, Prophet, Auto-ARIMA, LightGBM, Polynomial), Standard ranking with multiple metrics, walk-forward backtesting, and Auto per-product selection with rationale and CSV downloads.</p>
  </div>

  <script>
    (function(){
      const tabs = [
        {btn: document.getElementById('tab-forecaster'), panel: document.getElementById('panel-forecaster')},
        {btn: document.getElementById('tab-outlook'), panel: document.getElementById('panel-outlook')}
      ];
      function activate(i){
        tabs.forEach((t, idx) => {
          const active = idx === i;
          t.btn.classList.toggle('active', active);
          t.btn.setAttribute('aria-selected', active ? 'true' : 'false');
          t.panel.classList.toggle('active', active);
        });
      }
      tabs.forEach((t, i) => t.btn.addEventListener('click', () => activate(i)));
    })();
  </script>
</body>
</html>
